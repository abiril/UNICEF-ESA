{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.51.0\n"
     ]
    }
   ],
   "source": [
    "#pyTorch\n",
    "\n",
    "import azureml.core\n",
    "print(azureml.core.VERSION)\n",
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()\n",
    "\n",
    "from azureml.core import Environment\n",
    "\n",
    "curated_env = Environment.get(workspace=ws, name=\"abi_pytorch2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/azureuser/.local/lib/python3.8/site-packages (from torch) (4.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement rTorch (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for rTorch\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot\n",
    "import csv\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, make into tensors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMPOINTS</th>\n",
       "      <th>ID</th>\n",
       "      <th>land</th>\n",
       "      <th>pop</th>\n",
       "      <th>built_s</th>\n",
       "      <th>built_v</th>\n",
       "      <th>smod</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>147.0</td>\n",
       "      <td>611278.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.137907e+06</td>\n",
       "      <td>-363209.718402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>962773.0</td>\n",
       "      <td>478.437707</td>\n",
       "      <td>39625</td>\n",
       "      <td>99074</td>\n",
       "      <td>12</td>\n",
       "      <td>-4.137370e+06</td>\n",
       "      <td>-391241.256537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>201.0</td>\n",
       "      <td>975786.0</td>\n",
       "      <td>274.190113</td>\n",
       "      <td>22120</td>\n",
       "      <td>55308</td>\n",
       "      <td>12</td>\n",
       "      <td>-4.137350e+06</td>\n",
       "      <td>-392238.102079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4</td>\n",
       "      <td>324.0</td>\n",
       "      <td>993597.0</td>\n",
       "      <td>1056.169779</td>\n",
       "      <td>97516</td>\n",
       "      <td>243807</td>\n",
       "      <td>13</td>\n",
       "      <td>-4.136370e+06</td>\n",
       "      <td>-441241.256537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>187.361269</td>\n",
       "      <td>22986</td>\n",
       "      <td>57475</td>\n",
       "      <td>12</td>\n",
       "      <td>-4.136370e+06</td>\n",
       "      <td>-449241.256537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NUMPOINTS     ID       land          pop  built_s  built_v  smod  \\\n",
       "146          2  147.0   611278.0     0.000000        0        0    11   \n",
       "199          2  200.0   962773.0   478.437707    39625    99074    12   \n",
       "200          2  201.0   975786.0   274.190113    22120    55308    12   \n",
       "323          4  324.0   993597.0  1056.169779    97516   243807    13   \n",
       "331          2  332.0  1000000.0   187.361269    22986    57475    12   \n",
       "\n",
       "                x              y  \n",
       "146 -4.137907e+06 -363209.718402  \n",
       "199 -4.137370e+06 -391241.256537  \n",
       "200 -4.137350e+06 -392238.102079  \n",
       "323 -4.136370e+06 -441241.256537  \n",
       "331 -4.136370e+06 -449241.256537  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools = pandas.read_csv(\"/home/azureuser/cloudfiles/code/Users/ariley/Data/Schools/School_Counts/ceara_school_count_data.csv\")\n",
    "\n",
    "schools = schools.iloc[:, 3:]\n",
    "\n",
    "schools = schools.dropna()\n",
    "schools = schools[schools.NUMPOINTS > 0]\n",
    "\n",
    "schools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4731.000000\n",
       "mean        3.036356\n",
       "std         5.176254\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max       198.000000\n",
       "Name: NUMPOINTS, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools.NUMPOINTS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_ = schools.NUMPOINTS.mean()\n",
    "sigma_ = numpy.sqrt(schools.NUMPOINTS.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/meaneych/PyTorch_CountDistribution_Examples/blob/main/Poisson_PyTorch_Autograd.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.autograd.Variable(torch.from_numpy(schools.to_numpy())).type(torch.FloatTensor)\n",
    "l_mu = torch.autograd.Variable(torch.rand(1), requires_grad=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_nll(x, log_mu):\n",
    "    nll = -torch.sum(-torch.exp(log_mu) + x*torch.log(torch.exp(log_mu)) - torch.lgamma(x))\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  0 loglik  = -2199200300.0 l_mu = [-6631.6416] dL/dlmu =  [331622.3]\n",
      "Iteration =  10 loglik  = -2419146000.0 l_mu = [-7294.884] dL/dlmu =  [331622.3]\n",
      "Iteration =  20 loglik  = -2639092000.0 l_mu = [-7958.126] dL/dlmu =  [331622.3]\n",
      "Iteration =  30 loglik  = -2859038200.0 l_mu = [-8621.368] dL/dlmu =  [331622.3]\n",
      "Iteration =  40 loglik  = -3078984200.0 l_mu = [-9284.61] dL/dlmu =  [331622.3]\n",
      "Iteration =  50 loglik  = -3298930200.0 l_mu = [-9947.853] dL/dlmu =  [331622.3]\n",
      "Iteration =  60 loglik  = -3518875100.0 l_mu = [-10611.095] dL/dlmu =  [331622.3]\n",
      "Iteration =  70 loglik  = -3738821000.0 l_mu = [-11274.337] dL/dlmu =  [331622.3]\n",
      "Iteration =  80 loglik  = -3958767400.0 l_mu = [-11937.579] dL/dlmu =  [331622.3]\n",
      "Iteration =  90 loglik  = -4178713000.0 l_mu = [-12600.821] dL/dlmu =  [331622.3]\n"
     ]
    }
   ],
   "source": [
    "## Learning rate\n",
    "learning_rate = 2e-4\n",
    "\n",
    "## Training loop\n",
    "for t in range(100):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    loss = nn.PoissonNLLLoss()\n",
    "    NLLp = loss(l_mu, x)\n",
    "    NLLp.backward()\n",
    "    ## Logging to console\n",
    "    if t % 10 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLp.data.numpy(), \n",
    "              \"l_mu =\", l_mu.data.numpy(), \n",
    "              \"dL/dlmu = \", l_mu.grad.data.numpy())\n",
    "    ## SGD update of parms\n",
    "    l_mu.data -= learning_rate * l_mu.grad.data\n",
    "    ## Zero the gradients\n",
    "    l_mu.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-13264.063], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final estimate of Poisson mean parm\n",
    "[l_mu.data.numpy(), numpy.exp(l_mu.data.numpy())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try with just urban maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([474.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([  1. ,  20.7,  40.4,  60.1,  79.8,  99.5, 119.2, 138.9, 158.6,\n",
       "        178.3, 198. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schools = pandas.read_csv(\"/home/azureuser/cloudfiles/code/Users/ariley/Data/Schools/School_Counts/ceara_school_count_data.csv\")\n",
    "schools = schools.iloc[:, 3:]\n",
    "schools = schools.dropna()\n",
    "#schools = schools[schools[\"smod\"].isin([21,22,23,30])]\n",
    "schools = schools[schools[\"smod\"] == 30]\n",
    "schools = schools[schools.NUMPOINTS > 0]\n",
    "\n",
    "schools.head()\n",
    "matplotlib.pyplot.hist(schools.NUMPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  0 loglik  = 56152.69 l_mu = [0.8649193] dL/dlmu =  [64922.113]\n",
      "Iteration =  10 loglik  = -8373024.0 l_mu = [-128.97504] dL/dlmu =  [64919.74]\n",
      "Iteration =  20 loglik  = -16802172.0 l_mu = [-258.8145] dL/dlmu =  [64919.74]\n",
      "Iteration =  30 loglik  = -25231326.0 l_mu = [-388.654] dL/dlmu =  [64919.74]\n",
      "Iteration =  40 loglik  = -33660460.0 l_mu = [-518.49347] dL/dlmu =  [64919.74]\n",
      "Iteration =  50 loglik  = -42089630.0 l_mu = [-648.33295] dL/dlmu =  [64919.74]\n",
      "Iteration =  60 loglik  = -50518780.0 l_mu = [-778.1724] dL/dlmu =  [64919.74]\n",
      "Iteration =  70 loglik  = -58947910.0 l_mu = [-908.0119] dL/dlmu =  [64919.74]\n",
      "Iteration =  80 loglik  = -67377030.0 l_mu = [-1037.8513] dL/dlmu =  [64919.74]\n",
      "Iteration =  90 loglik  = -75806136.0 l_mu = [-1167.6902] dL/dlmu =  [64919.74]\n"
     ]
    }
   ],
   "source": [
    "mu_ = schools.NUMPOINTS.mean()\n",
    "sigma_ = numpy.sqrt(schools.NUMPOINTS.var())\n",
    "\n",
    "x = torch.autograd.Variable(torch.from_numpy(schools.to_numpy())).type(torch.FloatTensor)\n",
    "l_mu = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "\n",
    "## Learning rate\n",
    "learning_rate = 2e-4\n",
    "\n",
    "## Training loop\n",
    "for t in range(100):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    loss = nn.PoissonNLLLoss()\n",
    "    NLLp = loss(l_mu, x)\n",
    "    NLLp.backward()\n",
    "    ## Logging to console\n",
    "    if t % 10 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLp.data.numpy(), \n",
    "              \"l_mu =\", l_mu.data.numpy(), \n",
    "              \"dL/dlmu = \", l_mu.grad.data.numpy())\n",
    "    ## SGD update of parms\n",
    "    l_mu.data -= learning_rate * l_mu.grad.data\n",
    "    ## Zero the gradients\n",
    "    l_mu.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1297.529], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final estimate of Poisson mean parm\n",
    "[l_mu.data.numpy(), numpy.exp(l_mu.data.numpy())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-1 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMPOINTS</th>\n",
       "      <th>ID</th>\n",
       "      <th>land</th>\n",
       "      <th>pop</th>\n",
       "      <th>built_s</th>\n",
       "      <th>built_v</th>\n",
       "      <th>smod</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146928e+06</td>\n",
       "      <td>-415647.743962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146995e+06</td>\n",
       "      <td>-416168.514849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>89.137142</td>\n",
       "      <td>4644</td>\n",
       "      <td>11618</td>\n",
       "      <td>12</td>\n",
       "      <td>-4.145898e+06</td>\n",
       "      <td>-412699.018444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>8.601842</td>\n",
       "      <td>359</td>\n",
       "      <td>898</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146006e+06</td>\n",
       "      <td>-413307.519153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2.825484</td>\n",
       "      <td>141</td>\n",
       "      <td>353</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146103e+06</td>\n",
       "      <td>-414290.948276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NUMPOINTS   ID       land        pop  built_s  built_v  smod             x  \\\n",
       "0          0  1.0  1000000.0   0.000000        0        0    11 -4.146928e+06   \n",
       "1          0  2.0  1000000.0   0.000000        0        0    11 -4.146995e+06   \n",
       "2          0  3.0  1000000.0  89.137142     4644    11618    12 -4.145898e+06   \n",
       "3          0  4.0  1000000.0   8.601842      359      898    11 -4.146006e+06   \n",
       "4          0  5.0  1000000.0   2.825484      141      353    11 -4.146103e+06   \n",
       "\n",
       "               y  ind  \n",
       "0 -415647.743962    0  \n",
       "1 -416168.514849    0  \n",
       "2 -412699.018444    0  \n",
       "3 -413307.519153    0  \n",
       "4 -414290.948276    0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools = pandas.read_csv(\"/home/azureuser/cloudfiles/code/Users/ariley/Data/Schools/School_Counts/ceara_school_count_data.csv\")\n",
    "\n",
    "schools = schools.iloc[:, 3:]\n",
    "\n",
    "schools = schools.dropna()\n",
    "\n",
    "schools['ind'] = (schools[\"NUMPOINTS\"] > 0)\n",
    "\n",
    "schools.head()\n",
    "\n",
    "schools['ind'] = numpy.multiply(schools['ind'], 1)\n",
    "\n",
    "schools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/ariley/R-Code/Grid_Model/pyTorch_Grid_Model_non-zero.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f34643130396335302d373564342d343364382d393863322d3731366364313762626239372f7265736f7572636547726f7570732f52532d554e492d4f492d474947412f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f756e692d676967612d64617461736369656e63652f636f6d70757465732f6172696c657931/home/azureuser/cloudfiles/code/Users/ariley/R-Code/Grid_Model/pyTorch_Grid_Model_non-zero.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f34643130396335302d373564342d343364382d393863322d3731366364313762626239372f7265736f7572636547726f7570732f52532d554e492d4f492d474947412f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f756e692d676967612d64617461736369656e63652f636f6d70757465732f6172696c657931/home/azureuser/cloudfiles/code/Users/ariley/R-Code/Grid_Model/pyTorch_Grid_Model_non-zero.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m## Backprop on negative log likelihood loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f34643130396335302d373564342d343364382d393863322d3731366364313762626239372f7265736f7572636547726f7570732f52532d554e492d4f492d474947412f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f756e692d676967612d64617461736369656e63652f636f6d70757465732f6172696c657931/home/azureuser/cloudfiles/code/Users/ariley/R-Code/Grid_Model/pyTorch_Grid_Model_non-zero.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f34643130396335302d373564342d343364382d393863322d3731366364313762626239372f7265736f7572636547726f7570732f52532d554e492d4f492d474947412f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f756e692d676967612d64617461736369656e63652f636f6d70757465732f6172696c657931/home/azureuser/cloudfiles/code/Users/ariley/R-Code/Grid_Model/pyTorch_Grid_Model_non-zero.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     NLLp \u001b[39m=\u001b[39m loss(l_mu, x)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f34643130396335302d373564342d343364382d393863322d3731366364313762626239372f7265736f7572636547726f7570732f52532d554e492d4f492d474947412f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f756e692d676967612d64617461736369656e63652f636f6d70757465732f6172696c657931/home/azureuser/cloudfiles/code/Users/ariley/R-Code/Grid_Model/pyTorch_Grid_Model_non-zero.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     NLLp\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f34643130396335302d373564342d343364382d393863322d3731366364313762626239372f7265736f7572636547726f7570732f52532d554e492d4f492d474947412f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f756e692d676967612d64617461736369656e63652f636f6d70757465732f6172696c657931/home/azureuser/cloudfiles/code/Users/ariley/R-Code/Grid_Model/pyTorch_Grid_Model_non-zero.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m## Logging to console\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "mu_ = schools.ind.mean()\n",
    "sigma_ = numpy.sqrt(schools.ind.var())\n",
    "\n",
    "x = torch.autograd.Variable(torch.from_numpy(schools.to_numpy())).type(torch.FloatTensor)\n",
    "l_mu = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "\n",
    "\n",
    "## Learning rate\n",
    "learning_rate = 2e-4\n",
    "\n",
    "## Training loop\n",
    "for t in range(100):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    NLLp = loss(l_mu, x)\n",
    "    NLLp.backward()\n",
    "    ## Logging to console\n",
    "    if t % 10 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLp.data.numpy(), \n",
    "              \"l_mu =\", l_mu.data.numpy(), \n",
    "              \"dL/dlmu = \", l_mu.grad.data.numpy())\n",
    "    ## SGD update of parms\n",
    "    l_mu.data -= learning_rate * l_mu.grad.data\n",
    "    ## Zero the gradients\n",
    "    l_mu.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other variables \n",
    "\n",
    "y ~ b0 + b1* land + b2*pop + b3*built_s + b4*built_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMPOINTS</th>\n",
       "      <th>ID</th>\n",
       "      <th>land</th>\n",
       "      <th>population</th>\n",
       "      <th>built_s</th>\n",
       "      <th>built_v</th>\n",
       "      <th>smod</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146928e+06</td>\n",
       "      <td>-415647.743962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146995e+06</td>\n",
       "      <td>-416168.514849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>89.137142</td>\n",
       "      <td>4644</td>\n",
       "      <td>11618</td>\n",
       "      <td>12</td>\n",
       "      <td>-4.145898e+06</td>\n",
       "      <td>-412699.018444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>8.601842</td>\n",
       "      <td>359</td>\n",
       "      <td>898</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146006e+06</td>\n",
       "      <td>-413307.519153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2.825484</td>\n",
       "      <td>141</td>\n",
       "      <td>353</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.146103e+06</td>\n",
       "      <td>-414290.948276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NUMPOINTS   ID       land  population  built_s  built_v  smod  \\\n",
       "0          0  1.0  1000000.0    0.000000        0        0    11   \n",
       "1          0  2.0  1000000.0    0.000000        0        0    11   \n",
       "2          0  3.0  1000000.0   89.137142     4644    11618    12   \n",
       "3          0  4.0  1000000.0    8.601842      359      898    11   \n",
       "4          0  5.0  1000000.0    2.825484      141      353    11   \n",
       "\n",
       "              x              y  \n",
       "0 -4.146928e+06 -415647.743962  \n",
       "1 -4.146995e+06 -416168.514849  \n",
       "2 -4.145898e+06 -412699.018444  \n",
       "3 -4.146006e+06 -413307.519153  \n",
       "4 -4.146103e+06 -414290.948276  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools = pandas.read_csv(\"/home/azureuser/cloudfiles/code/Users/ariley/Data/Schools/School_Counts/ceara_school_count_data.csv\")\n",
    "\n",
    "schools = schools.iloc[:, 3:]\n",
    "\n",
    "schools = schools.dropna()\n",
    "schools.rename(columns = {\"pop\" : \"population\"}, inplace = True)\n",
    "\n",
    "schools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.autograd.Variable(torch.from_numpy(schools.land.to_numpy())).type(torch.FloatTensor)\n",
    "x2 = torch.autograd.Variable(torch.from_numpy(schools.population.to_numpy())).type(torch.FloatTensor)\n",
    "x3 = torch.autograd.Variable(torch.from_numpy(schools.built_s.to_numpy())).type(torch.FloatTensor)\n",
    "x4 = torch.autograd.Variable(torch.from_numpy(schools.built_v.to_numpy())).type(torch.FloatTensor)\n",
    "\n",
    "y = torch.autograd.Variable(torch.from_numpy(schools.NUMPOINTS.to_numpy())).type(torch.FloatTensor)\n",
    "\n",
    "b0 = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "b1 = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "b2 = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "b3 = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "b4 = torch.autograd.Variable(torch.rand(1), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_nll(x1, x2, x3, x4, y, b0, b1, b2, b3, b4):\n",
    "    nll = -torch.sum(-torch.exp(b0 + b1*x1 + b2*x2 + b3*x3 + b4*x4) + y*torch.log(torch.exp(b0 + b1*x1 + b2*x2 + b3*x3 + b4*x4)) - torch.lgamma(y))\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  0 loglik  = nan b0 = [0.49486542] b1 = [0.2714638] b2 = [0.981452] b3 = [0.69298154] b4 = [0.03178596] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  10 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  20 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  30 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  40 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  50 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  60 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  70 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  80 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  90 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  100 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  110 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  120 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  130 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  140 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  150 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  160 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  170 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  180 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n",
      "Iteration =  190 loglik  = nan b0 = [nan] b1 = [nan] b2 = [nan] b3 = [nan] b4 = [nan] dL/db0 =  [nan] dL/db1 =  [nan] dL/db2 =  [nan] dL/db3 =  [nan] dL/db4 =  [nan]\n"
     ]
    }
   ],
   "source": [
    "## Learning rate\n",
    "learning_rate_b0 = 2e-4\n",
    "learning_rate_b1 = 2e-4\n",
    "learning_rate_b2 = 2e-4\n",
    "learning_rate_b3 = 2e-4\n",
    "learning_rate_b4 = 2e-4\n",
    "\n",
    "\n",
    "## Training loop\n",
    "for t in range(200):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    NLLp = poisson_nll(x1=x1, x2=x2, x3=x3, x4=x4, y=y, b0=b0, b1=b1, b2=b2, b3=b3, b4=b4)\n",
    "    NLLp.backward()\n",
    "    ## Logging to console\n",
    "    if t % 10 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLp.data.numpy(), \n",
    "              \"b0 =\", b0.data.numpy(), \n",
    "              \"b1 =\", b1.data.numpy(),\n",
    "              \"b2 =\", b2.data.numpy(), \n",
    "              \"b3 =\", b3.data.numpy(), \n",
    "              \"b4 =\", b4.data.numpy(), \n",
    "              \"dL/db0 = \", b0.grad.data.numpy(),\n",
    "              \"dL/db1 = \", b1.grad.data.numpy(),\n",
    "              \"dL/db2 = \", b2.grad.data.numpy(),\n",
    "              \"dL/db3 = \", b3.grad.data.numpy(),\n",
    "              \"dL/db4 = \", b4.grad.data.numpy()\n",
    "             )\n",
    "    ## SGD update of parms\n",
    "    b0.data -= learning_rate_b0 * b0.grad.data\n",
    "    b1.data -= learning_rate_b1 * b1.grad.data\n",
    "    b2.data -= learning_rate_b2 * b2.grad.data\n",
    "    b3.data -= learning_rate_b3 * b3.grad.data\n",
    "    b4.data -= learning_rate_b4 * b4.grad.data\n",
    "    ## Zero the gradients\n",
    "    b0.grad.data.zero_()\n",
    "    b1.grad.data.zero_()\n",
    "    b2.grad.data.zero_()\n",
    "    b3.grad.data.zero_()\n",
    "    b4.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  0 loglik  = inf b0 = [0.40776038] b2 = [0.18912697] dL/db0 =  [inf] dL/db2 =  [inf]\n",
      "Iteration =  10 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  20 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  30 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  40 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  50 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  60 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  70 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  80 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  90 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  100 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  110 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  120 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  130 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  140 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  150 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  160 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  170 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  180 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n",
      "Iteration =  190 loglik  = nan b0 = [nan] b2 = [nan] dL/db0 =  [nan] dL/db2 =  [nan]\n"
     ]
    }
   ],
   "source": [
    "def poissonLoss(x2, y, b0, b2):\n",
    "    nll = torch.mean(torch.exp(b0 + b2*x2) - y*(b0 + b2*x2))\n",
    "    return nll\n",
    "\n",
    "## Learning rate\n",
    "learning_rate_b0 = 2e-4\n",
    "learning_rate_b2 = 2e-4\n",
    "\n",
    "\n",
    "\n",
    "## Training loop\n",
    "for t in range(200):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    NLLp = poissonLoss(x2=x2, y=y, b0=b0, b2=b2)\n",
    "    NLLp.backward()\n",
    "    ## Logging to console\n",
    "    if t % 10 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLp.data.numpy(), \n",
    "              \"b0 =\", b0.data.numpy(), \n",
    "              \"b2 =\", b2.data.numpy(), \n",
    "              \"dL/db0 = \", b0.grad.data.numpy(),\n",
    "              \"dL/db2 = \", b2.grad.data.numpy()\n",
    "             )\n",
    "    ## SGD update of parms\n",
    "    b0.data -= learning_rate_b0 * b0.grad.data\n",
    "    b2.data -= learning_rate_b2 * b2.grad.data\n",
    " \n",
    "    ## Zero the gradients\n",
    "    b0.grad.data.zero_()\n",
    "    b2.grad.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([nan], dtype=float32), array([nan], dtype=float32)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b0.data.numpy(), b2.data.numpy(), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
